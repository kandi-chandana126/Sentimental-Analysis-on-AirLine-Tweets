{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIJ7bLnmeqyO"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# Airline Tweet Classifier - 1000 Samples\n",
        "# DistilBERT + Focal Loss + 8 Epochs\n",
        "# Auto ZIP Export for Streamlit\n",
        "# ==========================================\n",
        "\n",
        "# 1. Install dependencies\n",
        "!pip install transformers datasets scikit-learn pandas torch evaluate -q\n",
        "\n",
        "# 2. Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import evaluate\n",
        "import joblib\n",
        "import shutil, os\n",
        "from google.colab import files\n",
        "\n",
        "# 3. Load dataset\n",
        "df = pd.read_csv(\"AirlineTweets.csv\")\n",
        "df = df[df[\"airline_sentiment\"].isin([\"positive\", \"neutral\", \"negative\"])]\n",
        "\n",
        "# Balance to ~1000 samples (333/class)\n",
        "samples_per_class = 333\n",
        "df_balanced = (\n",
        "    df.groupby(\"airline_sentiment\", group_keys=False)\n",
        "      .apply(lambda x: x.sample(min(len(x), samples_per_class), random_state=42))\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "text_column = \"text\"\n",
        "label_column = \"airline_sentiment\"\n",
        "\n",
        "# 4. Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "df_balanced[\"label\"] = label_encoder.fit_transform(df_balanced[label_column])\n",
        "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
        "\n",
        "# 5. Train-test split\n",
        "train_df, test_df = train_test_split(\n",
        "    df_balanced,\n",
        "    test_size=0.2,\n",
        "    stratify=df_balanced[\"label\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 6. Convert to Hugging Face Dataset\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# 7. Tokenizer\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(\n",
        "        example[text_column],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# 8. Remove unnecessary columns\n",
        "train_dataset = train_dataset.remove_columns([label_column, text_column, \"__index_level_0__\"])\n",
        "test_dataset = test_dataset.remove_columns([label_column, text_column, \"__index_level_0__\"])\n",
        "\n",
        "# 9. Compute class weights\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(train_df[\"label\"]),\n",
        "    y=train_df[\"label\"]\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# 10. Load model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(label_encoder.classes_)\n",
        ")\n",
        "\n",
        "# 11. Define Focal Loss\n",
        "class FocalLoss(torch.nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = torch.nn.functional.cross_entropy(inputs, targets, weight=self.alpha, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        return focal_loss\n",
        "\n",
        "focal_loss_fn = FocalLoss(alpha=class_weights.to(model.device), gamma=2)\n",
        "\n",
        "def compute_loss_with_focal(model, inputs, return_outputs=False):\n",
        "    labels = inputs.get(\"labels\")\n",
        "    outputs = model(**{k: v for k, v in inputs.items() if k != \"labels\"})\n",
        "    logits = outputs.get(\"logits\")\n",
        "    loss = focal_loss_fn(logits, labels)\n",
        "    return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "model.compute_loss = compute_loss_with_focal\n",
        "\n",
        "# 12. Metrics\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"],\n",
        "        \"f1\": f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"]\n",
        "    }\n",
        "\n",
        "# 13. Training args\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results_1000\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=8,  # longer training\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs_1000\",\n",
        "    load_best_model_at_end=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# 14. Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# 15. Train\n",
        "trainer.train()\n",
        "\n",
        "# 16. Evaluate\n",
        "eval_results = trainer.evaluate()\n",
        "print(\"\\nðŸ“Š Evaluation Results:\")\n",
        "for key, value in eval_results.items():\n",
        "    print(f\"{key}: {value:.4f}\")\n",
        "\n",
        "# 17. Save model\n",
        "model_dir = \"fine-tuned-airline-model-1000\"\n",
        "model.save_pretrained(model_dir)\n",
        "tokenizer.save_pretrained(model_dir)\n",
        "\n",
        "# 18. ZIP export for Streamlit\n",
        "zip_filename = \"streamlit_model_package.zip\"\n",
        "package_dir = \"streamlit_model_package\"\n",
        "\n",
        "shutil.rmtree(package_dir, ignore_errors=True)\n",
        "os.makedirs(package_dir, exist_ok=True)\n",
        "shutil.copytree(model_dir, f\"{package_dir}/{model_dir}\")\n",
        "shutil.copy(\"label_encoder.pkl\", f\"{package_dir}/label_encoder.pkl\")\n",
        "shutil.make_archive(\"streamlit_model_package\", 'zip', package_dir)\n",
        "\n",
        "files.download(zip_filename)"
      ]
    }
  ]
}